{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 03:11:41.356314: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-07 03:11:41.357609: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-07 03:11:41.378203: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-07 03:11:41.378225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-07 03:11:41.378878: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-07 03:11:41.382209: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-07 03:11:41.382836: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 03:11:41.877178: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-06-07 03:11:42.097522: I itex/core/wrapper/itex_cpu_wrapper.cc:70] Intel Extension for Tensorflow* AVX2 CPU backend is loaded.\n",
      "2024-06-07 03:11:42.152776: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-07 03:11:42.152929: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/slesche/.local/lib/python3.10/site-packages/bayesflow/trainers.py:27: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import levy_stable\n",
    "import tensorflow as tf\n",
    "\n",
    "import bayesflow as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.1\n"
     ]
    }
   ],
   "source": [
    "# Suppress scientific notation for floats\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Get rid of annoying tf warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_levy_trial(a=1, z=0.5, v=0, t=0.2, alpha=2.0, dt=0.001):\n",
    "    \"\"\"\n",
    "    Simulates the response time for one trial from a Lévy-Flight Process\n",
    "     * param a:     threshold separation (a>0)\n",
    "     * param z:     relative Starting Point (0<z<1)\n",
    "     * param v:     drift\n",
    "     * param t:     non-decisio-time (t>0)\n",
    "     * param alpha: stability parameter (0<a<2)\n",
    "     * param dt:    step size for simulation (dt>0)\n",
    "    \n",
    "    The function returns a simulated response time. A negative sign indicates a response at the lower threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = np.power(dt,(1/alpha)) / np.sqrt(2)\n",
    "    \n",
    "    bin_size = np.int_(1/dt)  # The decision path is simulated in bins of 1 second\n",
    "    start = [a*z]\n",
    "    cnt = 0\n",
    "\n",
    "    while(True):\n",
    "        path = np.array(start + np.cumsum(v*dt + levy_stable.rvs(alpha, 0, scale=scale, size=bin_size)))\n",
    "        if np.any(path < 0): \n",
    "            cnt = cnt + np.min(np.where(path < 0))\n",
    "            return (-(t + cnt*dt)).astype(np.float32)\n",
    "        \n",
    "        if np.any(path > a): \n",
    "            cnt = cnt + np.min(np.where(path > a))\n",
    "            return (t + cnt*dt).astype(np.float32)\n",
    "        \n",
    "        start = path[-1]\n",
    "        cnt = cnt + bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG = np.random.default_rng(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_prior():\n",
    "    \"\"\"\n",
    "    Draws one set of marginally informative priors for the 7-parameter Levy-Flight-Model\n",
    "    v1 nad v2 represent drift rates for two different stimulus types, \n",
    "    with positive and negative average slopes of evidence accumulation, respectively.\n",
    "    \n",
    "    The function returns a np array with all parameter values\n",
    "    \"\"\"\n",
    "    a      = RNG.gamma(3, 1/3) + 0.1\n",
    "    z      = 0.5#RNG.beta(5, 5)\n",
    "    v_pi   = RNG.normal(3, 3)\n",
    "    v_ni   = RNG.normal(3, 3)\n",
    "    t0     = RNG.gamma(1, 1/6) + 0.1\n",
    "    st0    = RNG.beta(1,2) * 2*t0\n",
    "    alpha  = RNG.beta (6, 2) * 2\n",
    "\n",
    "    return np.array([a, z, v_pi, v_ni, t0, st0, alpha]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_NAMES = ['a', 'z', 'v_pi', 'v_ni', 't', 'st', 'alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = bf.simulation.Prior(prior_fun=LF_prior, param_names=PARAM_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_experiment(theta, n_obs=500):\n",
    "    \"\"\"\n",
    "    Simulates response times for one participant of a lévy-flight experiment.\n",
    "     * param theta: numpy array with the parameters of the lfm (a,z,v1,v2,t,st,alpha) \n",
    "     * param n_obs: (maxiimum) number of observations\n",
    "    \n",
    "    The function returns a 2 by n_obs array, where the first column give the stimulus type (0,1)\n",
    "    and the second column gives teh response times (negative values indicate responese at the lower threshold)\n",
    "    \"\"\"\n",
    "    sim_data = np.zeros([n_obs,2])\n",
    "    cnd = np.random.randint(0,2,n_obs)\n",
    "    sim_data[:,0] = cnd;\n",
    "    for i in range(n_obs):\n",
    "        sim_data[i,1] = simulate_levy_trial(\n",
    "                            a = theta[0], \n",
    "                            z = 0.5,\n",
    "                            v = theta[2 + cnd[i]],\n",
    "                            t = np.random.uniform(theta[4] - theta[5]/2, theta[4] + theta[5]/2), \n",
    "                            alpha = theta[6]\n",
    "                        )   \n",
    "    return sim_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Performing 2 pilot runs with the lfm model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 7)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 500, 2)\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n"
     ]
    }
   ],
   "source": [
    "simulator = bf.simulation.Simulator(simulator_fun = LF_experiment)\n",
    "model = bf.simulation.GenerativeModel(prior=prior, simulator=simulator, name=\"lfm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_net = bf.networks.SetTransformer(input_dim=2, \n",
    "                                         summary_dim=21,\n",
    "                                             dense_settings = {'units': 256, 'activation': 'relu'},\n",
    "                                         num_dense_fc = 3,\n",
    "                                         name=\"lfm_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_net = bf.networks.InvertibleNetwork(\n",
    "    num_params=len(prior.param_names),\n",
    "    coupling_settings={\"dense_args\": dict(kernel_regularizer=None), \"dropout\": False},\n",
    "    num_coupling_layers = 12,\n",
    "    name=\"lfm_inference\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "amortizer = bf.amortizers.AmortizedPosterior(inference_net, summary_net, name=\"lfm_amortizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1 0.5 3.  3.  0.3 0.2 1.5]] [[0.6 0.  3.  3.  0.2 0.2 0.3]]\n"
     ]
    }
   ],
   "source": [
    "prior_means, prior_stds = prior.estimate_means_and_stds(n_draws=100000)\n",
    "prior_means = np.round(prior_means, decimals=1)\n",
    "prior_stds = np.round(prior_stds, decimals=1)\n",
    "print(prior_means, prior_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurator(forward_dict, min_trials=275, max_trials=300):\n",
    "    \"\"\"Configure the output of the GenerativeModel for a BayesFlow setup.\"\"\"\n",
    "\n",
    "    # Prepare placeholder dict\n",
    "    out_dict = {}\n",
    "\n",
    "    # Extract simulated response times\n",
    "    data = forward_dict[\"sim_data\"]\n",
    "    num_trials = np.random.randint(min_trials, max_trials + 1)\n",
    "    idx = np.random.choice(range(data.shape[1]), size=num_trials, replace=False)\n",
    "    data = data[:, idx, :]\n",
    "\n",
    "    out_dict[\"summary_conditions\"] = data.astype(np.float32)\n",
    "\n",
    "\n",
    "    # Make inference network aware of varying numbers of trials\n",
    "    # We create a vector of shape (batch_size, 1) by repeating the sqrt(num_obs)\n",
    "    vec_num_obs = np.sqrt(num_trials) * np.ones((data.shape[0], 1))\n",
    "    out_dict[\"direct_conditions\"] = np.sqrt(vec_num_obs).astype(np.float32)\n",
    "\n",
    "    # Get data generating parameters\n",
    "    params = forward_dict[\"prior_draws\"].astype(np.float32)\n",
    "\n",
    "    # Standardize parameters\n",
    "    out_dict[\"parameters\"] = ((params - prior_means) / prior_stds).astype(np.float32)\n",
    "\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialized empty loss history.\n",
      "INFO:root:Initialized networks from scratch.\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "/tmp/ipykernel_145793/3356660791.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  out_dict[\"parameters\"] = ((params - prior_means) / prior_stds).astype(np.float32)\n",
      "INFO:root:Done.\n"
     ]
    }
   ],
   "source": [
    "trainer = bf.trainers.Trainer(\n",
    "    generative_model=model, \n",
    "    amortizer=amortizer, \n",
    "    configurator=configurator,\n",
    "    default_lr=0.00005,\n",
    "    checkpoint_path=\"checkpoints//posner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 s, sys: 407 µs, total: 1.38 s\n",
      "Wall time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Attention: Takes about 5 minutes per 1,000 data sets!\n",
    "\n",
    "train_data = model(200000)\n",
    "\n",
    "f = open(\"training_data_posner.obj\",\"wb\")\n",
    "pickle.dump(train_data,f,protocol=4)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
