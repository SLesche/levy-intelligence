{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import levy_stable\n",
    "import tensorflow as tf\n",
    "\n",
    "import bayesflow as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress scientific notation for floats\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "# Get rid of annoying tf warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_levy_trial(a=1, z=0.5, v=0, t=0.2, alpha=2.0, dt=0.001):\n",
    "    \"\"\"\n",
    "    Simulates the response time for one trial from a Lévy-Flight Process\n",
    "     * param a:     threshold separation (a>0)\n",
    "     * param z:     relative Starting Point (0<z<1)\n",
    "     * param v:     drift\n",
    "     * param t:     non-decisio-time (t>0)\n",
    "     * param alpha: stability parameter (0<a<2)\n",
    "     * param dt:    step size for simulation (dt>0)\n",
    "    \n",
    "    The function returns a simulated response time. A negative sign indicates a response at the lower threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = np.power(dt,(1/alpha)) / np.sqrt(2)\n",
    "    \n",
    "    bin_size = np.int_(1/dt)  # The decision path is simulated in bins of 1 second\n",
    "    start = [a*z]\n",
    "    cnt = 0\n",
    "\n",
    "    while(True):\n",
    "        path = np.array(start + np.cumsum(v*dt + levy_stable.rvs(alpha, 0, scale=scale, size=bin_size)))\n",
    "        if np.any(path < 0): \n",
    "            cnt = cnt + np.min(np.where(path < 0))\n",
    "            return (-(t + cnt*dt)).astype(np.float32)\n",
    "        \n",
    "        if np.any(path > a): \n",
    "            cnt = cnt + np.min(np.where(path > a))\n",
    "            return (t + cnt*dt).astype(np.float32)\n",
    "        \n",
    "        start = path[-1]\n",
    "        cnt = cnt + bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG = np.random.default_rng(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_prior():\n",
    "    \"\"\"\n",
    "    Draws one set of marginally informative priors for the 7-parameter Levy-Flight-Model\n",
    "    v1 nad v2 represent drift rates for two different stimulus types, \n",
    "    with positive and negative average slopes of evidence accumulation, respectively.\n",
    "    \n",
    "    The function returns a np array with all parameter values\n",
    "    \"\"\"\n",
    "    a      = RNG.gamma(3, 1/3) + 0.1\n",
    "    z      = RNG.beta(5, 5)\n",
    "    v_pi   = RNG.normal(3, 3)\n",
    "    v_ni   = RNG.normal(3, 3)\n",
    "    t0     = RNG.gamma(1, 1/6) + 0.1\n",
    "    st0    = RNG.beta(1,2) * 2*t0\n",
    "    alpha  = RNG.beta (6, 2) * 2\n",
    "\n",
    "    return np.array([a, z, v_pi, v_ni, t0, st0, alpha]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_NAMES = ['a', 'z', 'v_pi', 'v_ni', 't', 'st', 'alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = bf.simulation.Prior(prior_fun=LF_prior, param_names=PARAM_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_experiment(theta, n_obs=500):\n",
    "    \"\"\"\n",
    "    Simulates response times for one participant of a lévy-flight experiment.\n",
    "     * param theta: numpy array with the parameters of the lfm (a,z,v1,v2,t,st,alpha) \n",
    "     * param n_obs: (maxiimum) number of observations\n",
    "    \n",
    "    The function returns a 2 by n_obs array, where the first column give the stimulus type (0,1)\n",
    "    and the second column gives teh response times (negative values indicate responese at the lower threshold)\n",
    "    \"\"\"\n",
    "    sim_data = np.zeros([n_obs,2])\n",
    "    cnd = np.random.randint(0,2,n_obs)\n",
    "    sim_data[:,0] = cnd;\n",
    "    for i in range(n_obs):\n",
    "        sim_data[i,1] = simulate_levy_trial(\n",
    "                            a = theta[0], \n",
    "                            z = theta[1],\n",
    "                            v = theta[2 + cnd[i]],\n",
    "                            t = np.random.uniform(theta[4] - theta[5]/2, theta[4] + theta[5]/2), \n",
    "                            alpha = theta[6]\n",
    "                        )   \n",
    "    return sim_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = bf.simulation.Simulator(simulator_fun = LF_experiment)\n",
    "model = bf.simulation.GenerativeModel(prior=prior, simulator=simulator, name=\"lfm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_net = bf.networks.SetTransformer(input_dim=2, \n",
    "                                         summary_dim=21,\n",
    "                                             dense_settings = {'units': 256, 'activation': 'relu'},\n",
    "                                         num_dense_fc = 3,\n",
    "                                         name=\"lfm_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_net = bf.networks.InvertibleNetwork(\n",
    "    num_params=len(prior.param_names),\n",
    "    coupling_settings={\"dense_args\": dict(kernel_regularizer=None), \"dropout\": False},\n",
    "    num_coupling_layers = 12,\n",
    "    name=\"lfm_inference\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amortizer = bf.amortizers.AmortizedPosterior(inference_net, summary_net, name=\"lfm_amortizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_means, prior_stds = prior.estimate_means_and_stds(n_draws=100000)\n",
    "prior_means = np.round(prior_means, decimals=1)\n",
    "prior_stds = np.round(prior_stds, decimals=1)\n",
    "print(prior_means, prior_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurator(forward_dict, min_trials=90, max_trials=500):\n",
    "    \"\"\"Configure the output of the GenerativeModel for a BayesFlow setup.\"\"\"\n",
    "\n",
    "    # Prepare placeholder dict\n",
    "    out_dict = {}\n",
    "\n",
    "    # Extract simulated response times\n",
    "    data = forward_dict[\"sim_data\"]\n",
    "    num_trials = np.random.randint(min_trials, max_trials + 1)\n",
    "    idx = np.random.choice(range(data.shape[1]), size=num_trials, replace=False)\n",
    "    data = data[:, idx, :]\n",
    "\n",
    "    out_dict[\"summary_conditions\"] = data.astype(np.float32)\n",
    "\n",
    "\n",
    "    # Make inference network aware of varying numbers of trials\n",
    "    # We create a vector of shape (batch_size, 1) by repeating the sqrt(num_obs)\n",
    "    vec_num_obs = np.sqrt(num_trials) * np.ones((data.shape[0], 1))\n",
    "    out_dict[\"direct_conditions\"] = np.sqrt(vec_num_obs).astype(np.float32)\n",
    "\n",
    "    # Get data generating parameters\n",
    "    params = forward_dict[\"prior_draws\"].astype(np.float32)\n",
    "\n",
    "    # Standardize parameters\n",
    "    out_dict[\"parameters\"] = ((params - prior_means) / prior_stds).astype(np.float32)\n",
    "\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = bf.trainers.Trainer(\n",
    "    generative_model=model, \n",
    "    amortizer=amortizer, \n",
    "    configurator=configurator,\n",
    "    default_lr=0.00005,\n",
    "    checkpoint_path=\"checkpoints//posner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Attention: Takes about 5 minutes per 1,000 data sets!\n",
    "\n",
    "train_data = model(200000)\n",
    "\n",
    "f = open(\"training_data_posner.obj\",\"wb\")\n",
    "pickle.dump(train_data,f,protocol=4)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
