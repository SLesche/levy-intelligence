---
title             : "Jump around! An investigation of the relationship between intelligence and the alpha parameter of the Levy-Flight Model"
shorttitle        : "Jump around!"

author: 
  - name          : "Sven Lesche"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Kurf√ºrsten-Anlage 57"
    email         : "sven.lesche@stud.uni-heidelberg.de"
  #   role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
  #     - "Conceptualization"
  #     - "Writing - Original Draft Preparation"
  #     - "Writing - Review & Editing"
  # - name          : "Author 2"
  #   affiliation   : "2"
  #   role:
  #     - "Supervision"

affiliation:
  - id            : "1"
    institution   : "Ruprecht-Karls-University Heidelberg"
  # - id            : "2"
  #   institution   : "Konstanz Business School"
  # add a second id using this syntax

authornote: |
  Code needed to replicate this work can be found at: https://github.com/SLesche/levy-intelligence.

# abstract: |
#   One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
#   
#   Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
#   
#   One sentence clearly stating the **general problem** being addressed by  this particular study.
#   
#   One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
#   
#   Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
#   
#   One or two sentences to put the results into a more **general context**.
#   
#   Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
#   
#   <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "intelligence, drift-diffusion model, levy-flight model"
# wordcount         : "X"

bibliography      : ["r-references.bib", "levy-flight.bib"] # put your ref files here

floatsintext      : yes # for pics in text
linenumbers       : no
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no
link-citations    : true # custom addin, makes citations link to reference section
# figsintext        : yes # custom addin

classoption       : "man"
# the settings below allow compilation of APA7 style citations/documents
header-includes:
  - |
    \makeatletter
    \renewcommand{\paragraph}{\@startsection{paragraph}{4}{\parindent}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-1em}%
      {\normalfont\normalsize\bfseries\typesectitle}}
    
    \renewcommand{\subparagraph}[1]{\@startsection{subparagraph}{5}{1em}%
      {0\baselineskip \@plus 0.2ex \@minus 0.2ex}%
      {-\z@\relax}%
      {\normalfont\normalsize\bfseries\itshape\hspace{\parindent}{#1}\textit{\addperi}}{\relax}}
    \makeatother
  - | 
    \raggedbottom
  - |
    \usepackage{hhline}
  - |
    \setlength{\parskip}{0pt}

csl               : "`r system.file('rmd', 'apa7.csl', package = 'papaja')`"
documentclass     : "apa7"
output            : papaja::apa6_word
---
```{r setup, include = FALSE}
# Working directory
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

# disallow tables breaking over pages
knitr::opts_chunk$set(ft.keepnext = TRUE,
                      ft.align = "left",
                      ft.latex.float = "float")
# Seed for random number generation
set.seed(1234)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed) # this adds random seed to all chunks
knitr::opts_chunk$set(autodep = TRUE)
knitr::dep_auto()
library(papaja)
source("helper_functions.R")
source("investigating_results.R")
source("sem_levy_models.R")

r_refs("r-references.bib")

r_citations <- cite_r(
  file = "r-references.bib",
  pkgs = c("papaja", "tidyverse", "knitr", "rmarkdown", "lavaan", "flextable"),
  omit = FALSE,
  footnote = TRUE
  )
```

<!-- Setup -->
<!-- Maybe setup R libraries here -->

<!-- Here we can incorporate child markdown-documents as the separate parts -->
# Introduction
Intelligence is one of the most well researched constructs in psychology, playing a crucial role in predicting success in education, job performance, and overall well-being. Understanding the cognitive processes that underpin intelligence has been the focus of decades of research. One of the most robust findings in this area is the relationship between measures of mental speed and intelligence, with faster cognitive processing often associated with higher intelligence.

In a review of 172 studies, @sheppard2008intelligence reported an average correlation of $r = -.24$ between various mental speed measures and various intelligence measures. Most studies investigating the relationship between intelligence and mental speed use elementary cognitive tasks (ECTs) to obtain a measure of mental speed. ECTs are simple tasks with very low cognitive demands. For example, participants have to respond by key-press in which of two squares a stimulus has appeared. This limits the role of individual differences in strategy and allows researchers to obtain a pure measure of mental speed.

Mental speed is assessed at different levels: behaviorally, through psychophysiological measures, or via cognitive models. On a behavioral level, researchers find robust negative correlations between intelligence and both mean response time and variability of response time [@jensen2006clocking; @doebler2016relationship]. More intelligent individuals tend to have lower mean response times and lower variability in response times. Using EEG measures, @schubert2017general found that the latency of event-related potentials are able to explain 80% of the variance in intelligence. In cognitive models, evidence accumulation models like the drift-diffusion model (DDM) [@ratcliff2008diffusion] are employed to obtain model parameters of mental speed. 

The DDM assumes that participants steadily accumulate evidence during a trial. Once they have accumulated enough evidence pointing towards a response, a decision and subsequent reaction is made.
The model attempts to fit the empirical distribution of response times and accuracies by optimizing several different parameters. First, response time is separated into decision time, where the noisy evidence accumulation process takes place, and non-decision time $T_{er}$. Non-decision time incorporates processes such as stimulus encoding and motor processes. Decision time is further controlled by three main parameters: (1) the boundary separation $a$ describes the distance between decision boundaries and represents the amount of evidence required to reach a decision, (2) the mean drift rate $v$ is the average rate at which evidence is accumulated and (3) the mean starting point _z_ represents the average point at which the evidence accumulation process begins and can account for an a-priori bias towards one of the two-choice alternatives. 

Further parameters of across-trial variability can be added to reflect changes in diffusion model parameters over time. Variability of the starting point _s~z~_ accounts for differences in a-priori bias towards one response alternative across trials [@laming1968information; @ratcliff1998modeling]. Variability of drift rate $\eta$ reflects changes in drift rate across trials and allows the model to account for systematic differences between trials, such as error responses being systematically faster than correct responses [@ratcliff1978theory; @ratcliff1998modeling]. Finally, variability of non-decision time _s~t~_ reflects fluctuations in the duration of encoding or motor-execution processes across trials.

Of these parameters, drift rate has so far shown the most robust correlation to intelligence [@schubert2015decomposing; @schmiedek2007individual; @ratcliff2011effects]. Boundary separation is often negatively associated with intelligence, but the effect is smaller than for drift rates [@schubert2015decomposing; @ratcliff2011effects].

In both the simple and full DDM, the drift rate is an average rate of evidence accumulation. In each step, this average rate is influenced by noise, resulting in the random walk with a certain drift that characterizes the evidence accumulation process. This noise is assumed to be normally distributed with a mean of 0. The standard deviation of the noise distribution is the "diffusion constant" and is set to 1 in most applications.

Under the assumption that noise is normally distributed, large jumps in accumulated evidence become very unlikely. Recently, @voss2019sequential introduced an extension of the DDM that modifies the noise distribution. Here, the normal distribution is replaced by a heavy tailed distribution. This increases the likelihood of larger jumps occurring in the evidence accumulation process. The Cauchy distribution is an example of such a heavy-tailed distribution. Both the Cauchy distribution and the normal distribution are specific instances of the family of so-called Levy alpha-stable distributions. Within this family, a stability parameter $\alpha$ governs the heaviness in the tails of the distribution. $\alpha$ = 2 results in the normal distribution, $\alpha$ = 1 results in the Cauchy distribution. In the Levy-flight model, $\alpha$ is an additional parameter that can be estimated from the data [@voss2019sequential; @wieschen2020jumping]. 

Higher values of $\alpha$ lead to more stable evidence accumulation with fewer jumps. Lower values of $alpha$ lead to less stable evidence accumulation, showing more extreme jumps. In behavioral data, higher variability of response times is associated with lower intelligence [@doebler2016relationship]. Intelligent individuals are more "stable" in their response times. Following these findings, higher values of $\alpha$ may be positively associated with intelligence. @wieschen2020jumping refers to this as the "inefficient jumping" hypothesis. The jumps in evidence accumulation more common in heavy-tailed noise distributions are deemed inefficient while completing the response time task. Intelligent individuals should therefore display fewer inefficient jumps and thus have higher values of $\alpha$.

Contrasting this, jumps in evidence accumulation may also be beneficial. In simple response time tasks with high accuracy, erratically accumulating information may be an efficient way to decrease response times. This is termed the "efficient jumping" hypothesis [@wieschen2020jumping]. The efficient jumping hypothesis claims that more intelligent individuals make use of larger jumps in evidence accumulation to complete the task more quickly. They should therefore display lower values of $\alpha$.

This present work aims to provide a first insight into the question of efficient vs. inefficient jumping. To this end, I applied the Levy-flight model to data from three different response time tasks and investigated the correlation between the $\alpha$ parameter and intelligence. Following @schubert2016trait, I used structural equation modeling to obtain a latent factor for both $\alpha$ and intelligence to account for measurement error. 

The inefficient jumping hypothesis predicts positive latent correlations between $\alpha$ and _g_. More intelligent individuals display smaller heavy-tails. The efficient jumping hypothesis predicts negative correlations between $\alpha$ and _g_. More intelligent individuals make efficient use of jumps in evidence accumulation and thus display heavier tails.

# Methods
## Participants
The data I analyse here was published in @schubert2017general. The original study consisted of three measurement occasions and included EEG measurements in the first and last measurement occasion. The present analysis focuses on the behavioral data collected during the first two measurement occasions. The sample consists of N = 122 (72 female, $M_{age} = 36.7, SD_{age} = 13.6$) participants. All of the participants had normal or corrected to normal vision, no history of mental illness, provided informed consent, and received 100‚Ç¨ for their participation. 

## Materials
I will focus on behavioral data from the Hick, Sternberg, and Posner Tasks. Detailed information can be found in the original publication [@schubert2017general].

Intelligence was measured using a computer-adapted version of Raven's Advanced Progressive Matrices (APM) [@raven1981manual] and the Berlin Intelligence Structure Test (BIS) [@jager1997berliner].

## Procedure
The first two measurement occasions were spaced approximately four months apart. The Hick, Sternberg, and Posner Tasks were administered at the first measurement occasion in the same order for all participants. The APM and BIS were administered at the second measurement occasion.

## Analysis
### Levy-Flight Model
I estimated the parameters of the Levy-Flight model using BayesFlow [@radev2020bayesflow]. I used accuracy coding, with the upper boundary representing a correct response and the lower boundary representing an incorrect response. Hence, I fixed the start point $z$ to 0.5. I allowed drift rate $v$, boundary separation $a$, non-decision time $t0$, variability in the non-decision time $st0$ and $\alpha$ to vary between tasks and conditions.

To train the neural approximator, I employed the following priors:
$$v \sim Normal(3,3)$$
$$a \sim Gamma(5, 2) + 0.1$$
$$t0 \sim Gamma(1, 3) + 0.1$$
$$st0 \sim Beta(1, 3) \cdot 2 \cdot t0$$
$$\alpha \sim Beta(4, 2) \cdot 2$$
I simulated 200,000 datasets and then trained the model for 150 epochs. After training, I investigated the computational faithfulness of the neural network by using simulation-based calibration [@talts2018validating]. I investigated the bias of the posterior distributions after applying the amortized inference network on newly simulated data. Furthermore, I investigated the ability of the model to recover true generating parameters by comparing the recovered posterior means to the true parameters used in simulation.

### Structural Equation Model
I used structural equation modelling to evaluate the correlation between a latent first order factor of the $\alpha$ parameter over all tasks and a _g_ factor over all intelligence measures. In addition to the first order factor over all tasks and conditions, I included task-specific method factors. Intelligence was defined as a first order factor over all sub-tests of the BIS as well as the APM. I then investigated the relationship between the latent factors $\alpha$ and _g_.

# Results
Model estimation was done in Python 3.11 with Bayesflow version 1.1.6 [@radev2020bayesflow]. Data preparation and analysis was completed in `r r_citations$r`. `r r_citations$pkgs`

I excluded all response times which deviated more than 3 standard deviations from the mean response time for a given participant in a given condition. This removed `r round(hick_data_removed*100, 2)` % of the data in the Hick task, `r round(posner_data_removed*100, 2)` % of the data in the Posner task, and `r round(sternberg_data_removed*100, 2)` % of the data in the Sternberg task. No further data-pruning was applied.

## Levy Flight Model estimation
The inference net showed no sign of bias in posterior estimation (see Figure \@ref(fig:results-bf-bias)). It also displayed acceptable recovery of true generating parameters (see Figure \@ref(fig:results-bf-recovery)).

## Relationship of $\alpha$ and g
On a bivariate level, $\alpha$ displayed consistently negative correlations with all cognitive performance measures (see Figure \@ref(fig:results-bivariate-plot)). Averaged over tasks and conditions, $\alpha$ showed a correlation with performance in the APM of $r =$`r results %>% filter(measure == "APM", param == "alpha") %>% pull(cor) %>% fisher_cor_mean()` and $r =$`r results %>% filter(measure == "BIS", param == "alpha") %>% pull(cor) %>% fisher_cor_mean()` in the BIS.

(ref:results-bivariate-plot) Bivariate Correlation between parameters and cognitive performance
```{r results-bivariate-plot, fig.cap = paste("(ref:results-bivariate-plot)")}
plot_by_measure
```

## SEM
The model showed acceptable fit `r print_sem(alpha_g)` and can be seen in Figure \@ref(fig:results-sem-alpha). On a latent level $\alpha$ and _g_ correlated to $r = -.35$. 

(ref:results-sem-alpha) Structural equation model of the relationship between $\alpha$ and intelligence
```{r results-sem-alpha, fig.cap = paste("(ref:results-sem-alpha)")}
knitr::include_graphics(
  "images/sem_alpha_plot.png"
)
```

# Discussion
In this work, I applied a Levy-Flight Model [@voss2019sequential] to data from three different tasks [@schubert2017general] in order to investigate the relationship between the stability parameter $\alpha$ and intelligence. Bivariate correlations between $\alpha$ and measures of mental speed were negative with an average correlation of $r =$`r results %>% filter(measure %in% c("APM", "C", "PS", "M", "P"), param == "alpha") %>% pull(cor) %>% fisher_cor_mean()`. Following @schubert2016trait, we also investigated these results using SEM to obtain a latent trait measure for $\alpha$. The latent correlation between $\alpha$ and intelligence was $r = -.35$. 

This negative correlation provides support for the efficient jumping hypothesis [@wieschen2020jumping]. More intelligent individuals display less stable evidence accumulation processes. This indicates that they make use of this instability in easy response time tasks in order to optimize speed and accuracy.

These results stand in contrast to earlier findings showing a negative correlation between variance in the response times and intelligence [@doebler2016relationship]. More intelligent individuals display less variability. These differing results suggest that $\alpha$ is not a measure of variability, despite the intuitive similarity between variability and instability. Additionally, $\alpha$ shows stronger average correlations with mean response time $r =$ `r results %>% filter(measure == "mean_rt", param == "alpha") %>% pull(cor) %>% fisher_cor_mean()` than with the standard deviation of response time $r =$ `r results %>% filter(measure == "sd_rt", param == "alpha") %>% pull(cor) %>% fisher_cor_mean()`. These correlations suggest that stability in the evidence accumulation process leads to higher average response times and slightly higher variability in the response times.

Future research should focus on investigating more difficult response time tasks. The relationship between $\alpha$ and intelligence may change in tasks that require more higher-order processing. I expect that the functional benefits of instability in the evidence accumulation process are only present in simple tasks and will revert in more complex tasks [@wieschen2020jumping].

Nonetheless, this work provides first insights into the functionality of stability in evidence accumulation processes. My results suggest that more intelligent individuals display less stability in order to improve the response time by allowing bigger jumps in evidence accumulation processes. Future work will focus on investigating this relationship in more complex tasks, where I expect the functionality of instability to decline.

<!-- References -->
\newpage

# References
::: {#refs custom-style="Bibliography"}
:::

# (APPENDIX) Appendix {-}

(ref:results-bf-bias) Empirical cumulative density functions of rank statistics
```{r results-bf-bias, fig.cap = paste("(ref:results-bf-bias)")}
knitr::include_graphics(
  "images/bias_plot.png"
)
```

(ref:results-bf-recovery) Recovery of true model parameters
```{r results-bf-recovery, fig.cap = paste("(ref:results-bf-recovery)")}
knitr::include_graphics(
  "images/recovery_plot.png"
)
```

(ref:results-corr-matrix) Correlation matrix of behavioral data and model parameters. Task and condition labels are omitted to improve readability
```{r results-corr-matrix, fig.cap = paste("(ref:results-corr-matrix)")}
knitr::include_graphics(
  "images/corplot.png"
)
```
